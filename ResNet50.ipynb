{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b2b366f-db87-4f51-8c06-a0059cf19ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])  # ImageNet标准化\n",
    "])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((40, 40)),  # 先放大\n",
    "    transforms.RandomCrop(32),     # 再随机裁剪\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])  # ImageNet标准化\n",
    "])\n",
    "batch_size=4\n",
    "trainset=torchvision.datasets.CIFAR10(root=r'./',train=True,download=True,transform=transform_train)\n",
    "testset=torchvision.datasets.CIFAR10(root=r'./',train=False,download=True,transform=transform)\n",
    "trainloader=torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "testloader=torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "classes=('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffe459d4-e9fa-4449-a48b-3fa7b83a0872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from torch.nn import MultiheadAttention\n",
    "# 检查GPU可用性\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "\n",
    "\n",
    "# 修改最后一层全连接层（适配10分类）\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 10)  # CIFAR10有10个类别\n",
    ")\n",
    "\n",
    "# 启用新添加层的梯度\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 转移到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe18b45f-f883-4512-968e-616fdc8ce6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Batch [2000/12500], Loss: 2.2165, Acc: 16.99%\n",
      "Epoch [1/30], Batch [4000/12500], Loss: 2.0393, Acc: 24.70%\n",
      "Epoch [1/30], Batch [6000/12500], Loss: 1.9215, Acc: 30.51%\n",
      "Epoch [1/30], Batch [8000/12500], Loss: 1.8616, Acc: 32.92%\n",
      "Epoch [1/30], Batch [10000/12500], Loss: 1.7193, Acc: 38.33%\n",
      "Epoch [1/30], Batch [12000/12500], Loss: 1.8164, Acc: 36.35%\n",
      "Epoch 1, Validation Loss: 3.5722, Accuracy: 40.36%, LR: 0.000088\n",
      "Epoch [2/30], Batch [2000/12500], Loss: 1.7319, Acc: 39.48%\n",
      "Epoch [2/30], Batch [4000/12500], Loss: 1.6088, Acc: 44.54%\n",
      "Epoch [2/30], Batch [6000/12500], Loss: 1.5077, Acc: 48.27%\n",
      "Epoch [2/30], Batch [8000/12500], Loss: 1.4657, Acc: 48.51%\n",
      "Epoch [2/30], Batch [10000/12500], Loss: 1.6609, Acc: 42.59%\n",
      "Epoch [2/30], Batch [12000/12500], Loss: 1.6187, Acc: 45.05%\n",
      "Epoch 2, Validation Loss: 1.4409, Accuracy: 56.98%, LR: 0.000089\n",
      "Epoch [3/30], Batch [2000/12500], Loss: 1.5625, Acc: 46.71%\n",
      "Epoch [3/30], Batch [4000/12500], Loss: 1.4917, Acc: 49.71%\n",
      "Epoch [3/30], Batch [6000/12500], Loss: 1.4182, Acc: 52.24%\n",
      "Epoch [3/30], Batch [8000/12500], Loss: 1.3779, Acc: 53.85%\n",
      "Epoch [3/30], Batch [10000/12500], Loss: 1.3394, Acc: 55.40%\n",
      "Epoch [3/30], Batch [12000/12500], Loss: 1.2648, Acc: 57.80%\n",
      "Epoch 3, Validation Loss: 1.6908, Accuracy: 64.37%, LR: 0.000008\n",
      "Epoch [4/30], Batch [2000/12500], Loss: 1.2241, Acc: 59.65%\n",
      "Epoch [4/30], Batch [4000/12500], Loss: 1.2753, Acc: 57.51%\n",
      "Epoch [4/30], Batch [6000/12500], Loss: 1.4748, Acc: 51.52%\n",
      "Epoch [4/30], Batch [8000/12500], Loss: 1.4684, Acc: 50.94%\n",
      "Epoch [4/30], Batch [10000/12500], Loss: 1.4607, Acc: 51.21%\n",
      "Epoch [4/30], Batch [12000/12500], Loss: 1.4295, Acc: 53.06%\n",
      "Epoch 4, Validation Loss: 1.2172, Accuracy: 65.53%, LR: 0.000089\n",
      "Epoch [5/30], Batch [2000/12500], Loss: 1.4036, Acc: 53.86%\n",
      "Epoch [5/30], Batch [4000/12500], Loss: 1.3784, Acc: 54.77%\n",
      "Epoch [5/30], Batch [6000/12500], Loss: 1.3310, Acc: 56.44%\n",
      "Epoch [5/30], Batch [8000/12500], Loss: 1.3141, Acc: 56.66%\n",
      "Epoch [5/30], Batch [10000/12500], Loss: 1.2890, Acc: 58.01%\n",
      "Epoch [5/30], Batch [12000/12500], Loss: 1.2622, Acc: 58.59%\n",
      "Epoch 5, Validation Loss: 1.0507, Accuracy: 68.52%, LR: 0.000046\n",
      "Epoch [6/30], Batch [2000/12500], Loss: 1.2042, Acc: 61.20%\n",
      "Epoch [6/30], Batch [4000/12500], Loss: 1.1698, Acc: 62.41%\n",
      "Epoch [6/30], Batch [6000/12500], Loss: 1.1569, Acc: 62.31%\n",
      "Epoch [6/30], Batch [8000/12500], Loss: 1.1288, Acc: 63.77%\n",
      "Epoch [6/30], Batch [10000/12500], Loss: 1.1169, Acc: 63.98%\n",
      "Epoch [6/30], Batch [12000/12500], Loss: 1.0754, Acc: 65.35%\n",
      "Epoch 6, Validation Loss: 0.9255, Accuracy: 72.71%, LR: 0.000008\n",
      "Epoch [7/30], Batch [2000/12500], Loss: 1.0334, Acc: 66.45%\n",
      "Epoch [7/30], Batch [4000/12500], Loss: 1.0476, Acc: 66.34%\n",
      "Epoch [7/30], Batch [6000/12500], Loss: 1.0212, Acc: 66.96%\n",
      "Epoch [7/30], Batch [8000/12500], Loss: 1.1930, Acc: 61.95%\n",
      "Epoch [7/30], Batch [10000/12500], Loss: 1.3451, Acc: 56.65%\n",
      "Epoch [7/30], Batch [12000/12500], Loss: 1.3341, Acc: 57.27%\n",
      "Epoch 7, Validation Loss: 1.0531, Accuracy: 67.99%, LR: 0.000099\n",
      "Epoch [8/30], Batch [2000/12500], Loss: 1.3382, Acc: 56.41%\n",
      "Epoch [8/30], Batch [4000/12500], Loss: 1.3233, Acc: 56.94%\n",
      "Epoch [8/30], Batch [6000/12500], Loss: 1.3222, Acc: 57.24%\n",
      "Epoch [8/30], Batch [8000/12500], Loss: 1.3004, Acc: 57.10%\n",
      "Epoch [8/30], Batch [10000/12500], Loss: 1.2950, Acc: 58.30%\n",
      "Epoch [8/30], Batch [12000/12500], Loss: 1.2888, Acc: 58.39%\n",
      "Epoch 8, Validation Loss: 0.9848, Accuracy: 69.14%, LR: 0.000089\n",
      "Epoch [9/30], Batch [2000/12500], Loss: 1.2606, Acc: 59.34%\n",
      "Epoch [9/30], Batch [4000/12500], Loss: 1.2573, Acc: 59.17%\n",
      "Epoch [9/30], Batch [6000/12500], Loss: 1.2418, Acc: 59.76%\n",
      "Epoch [9/30], Batch [8000/12500], Loss: 1.2319, Acc: 59.61%\n",
      "Epoch [9/30], Batch [10000/12500], Loss: 1.2115, Acc: 61.12%\n",
      "Epoch [9/30], Batch [12000/12500], Loss: 1.1910, Acc: 61.33%\n",
      "Epoch 9, Validation Loss: 0.9769, Accuracy: 69.95%, LR: 0.000070\n",
      "Epoch [10/30], Batch [2000/12500], Loss: 1.1918, Acc: 61.51%\n",
      "Epoch [10/30], Batch [4000/12500], Loss: 1.1748, Acc: 62.51%\n",
      "Epoch [10/30], Batch [6000/12500], Loss: 1.1549, Acc: 63.34%\n",
      "Epoch [10/30], Batch [8000/12500], Loss: 1.1312, Acc: 63.66%\n",
      "Epoch [10/30], Batch [10000/12500], Loss: 1.1202, Acc: 64.09%\n",
      "Epoch [10/30], Batch [12000/12500], Loss: 1.1184, Acc: 63.95%\n",
      "Epoch 10, Validation Loss: 1.0074, Accuracy: 70.32%, LR: 0.000046\n",
      "Epoch [11/30], Batch [2000/12500], Loss: 1.0928, Acc: 65.54%\n",
      "Epoch [11/30], Batch [4000/12500], Loss: 1.0878, Acc: 65.17%\n",
      "Epoch [11/30], Batch [6000/12500], Loss: 1.0770, Acc: 65.44%\n",
      "Epoch [11/30], Batch [8000/12500], Loss: 1.0222, Acc: 67.19%\n",
      "Epoch [11/30], Batch [10000/12500], Loss: 1.0408, Acc: 67.19%\n",
      "Epoch [11/30], Batch [12000/12500], Loss: 1.0042, Acc: 67.99%\n",
      "Epoch 11, Validation Loss: 0.9551, Accuracy: 72.68%, LR: 0.000024\n",
      "Epoch [12/30], Batch [2000/12500], Loss: 0.9984, Acc: 68.88%\n",
      "Epoch [12/30], Batch [4000/12500], Loss: 0.9976, Acc: 69.03%\n",
      "Epoch [12/30], Batch [6000/12500], Loss: 0.9806, Acc: 69.31%\n",
      "Epoch [12/30], Batch [8000/12500], Loss: 0.9566, Acc: 70.30%\n",
      "Epoch [12/30], Batch [10000/12500], Loss: 0.9740, Acc: 69.36%\n",
      "Epoch [12/30], Batch [12000/12500], Loss: 0.9694, Acc: 69.66%\n",
      "Epoch 12, Validation Loss: 0.7723, Accuracy: 75.79%, LR: 0.000008\n",
      "Epoch [13/30], Batch [2000/12500], Loss: 0.9483, Acc: 70.44%\n",
      "Epoch [13/30], Batch [4000/12500], Loss: 0.9413, Acc: 70.06%\n",
      "Epoch [13/30], Batch [6000/12500], Loss: 0.9444, Acc: 70.42%\n",
      "Epoch [13/30], Batch [8000/12500], Loss: 0.9174, Acc: 71.20%\n",
      "Epoch [13/30], Batch [10000/12500], Loss: 0.9398, Acc: 71.04%\n",
      "Epoch [13/30], Batch [12000/12500], Loss: 0.9292, Acc: 70.51%\n",
      "Epoch 13, Validation Loss: 0.7795, Accuracy: 75.68%, LR: 0.000001\n",
      "Epoch [14/30], Batch [2000/12500], Loss: 0.9641, Acc: 70.03%\n",
      "Epoch [14/30], Batch [4000/12500], Loss: 1.2158, Acc: 61.80%\n",
      "Epoch [14/30], Batch [6000/12500], Loss: 1.2413, Acc: 60.35%\n",
      "Epoch [14/30], Batch [8000/12500], Loss: 1.2234, Acc: 60.70%\n",
      "Epoch [14/30], Batch [10000/12500], Loss: 1.2155, Acc: 60.84%\n",
      "Epoch [14/30], Batch [12000/12500], Loss: 1.2285, Acc: 60.52%\n",
      "Epoch 14, Validation Loss: 1.0083, Accuracy: 69.00%, LR: 0.000099\n",
      "Epoch [15/30], Batch [2000/12500], Loss: 1.2528, Acc: 59.52%\n",
      "Epoch [15/30], Batch [4000/12500], Loss: 1.2291, Acc: 60.79%\n",
      "Epoch [15/30], Batch [6000/12500], Loss: 1.2039, Acc: 61.26%\n",
      "Epoch [15/30], Batch [8000/12500], Loss: 1.2396, Acc: 60.58%\n",
      "Epoch [15/30], Batch [10000/12500], Loss: 1.2362, Acc: 60.09%\n",
      "Epoch [15/30], Batch [12000/12500], Loss: 1.2014, Acc: 61.49%\n",
      "Epoch 15, Validation Loss: 0.9761, Accuracy: 69.09%, LR: 0.000095\n",
      "Epoch [16/30], Batch [2000/12500], Loss: 1.2130, Acc: 60.96%\n",
      "Epoch [16/30], Batch [4000/12500], Loss: 1.2242, Acc: 60.08%\n",
      "Epoch [16/30], Batch [6000/12500], Loss: 1.1856, Acc: 62.35%\n",
      "Epoch [16/30], Batch [8000/12500], Loss: 1.2156, Acc: 61.46%\n",
      "Epoch [16/30], Batch [10000/12500], Loss: 1.2006, Acc: 61.49%\n",
      "Epoch [16/30], Batch [12000/12500], Loss: 1.2094, Acc: 61.42%\n",
      "Epoch 16, Validation Loss: 1.0039, Accuracy: 68.88%, LR: 0.000089\n",
      "Epoch [17/30], Batch [2000/12500], Loss: 1.1983, Acc: 61.54%\n",
      "Epoch [17/30], Batch [4000/12500], Loss: 1.1605, Acc: 63.06%\n",
      "Epoch [17/30], Batch [6000/12500], Loss: 1.1809, Acc: 61.81%\n",
      "Epoch [17/30], Batch [8000/12500], Loss: 1.1716, Acc: 62.19%\n",
      "Epoch [17/30], Batch [10000/12500], Loss: 1.1773, Acc: 61.80%\n",
      "Epoch [17/30], Batch [12000/12500], Loss: 1.1623, Acc: 63.20%\n",
      "Epoch 17, Validation Loss: 1.0063, Accuracy: 70.65%, LR: 0.000080\n",
      "Epoch [18/30], Batch [2000/12500], Loss: 1.1488, Acc: 63.16%\n",
      "Epoch [18/30], Batch [4000/12500], Loss: 1.1510, Acc: 63.12%\n",
      "Epoch [18/30], Batch [6000/12500], Loss: 1.1326, Acc: 63.89%\n",
      "Epoch [18/30], Batch [8000/12500], Loss: 1.1396, Acc: 63.54%\n",
      "Epoch [18/30], Batch [10000/12500], Loss: 1.1347, Acc: 63.26%\n",
      "Epoch [18/30], Batch [12000/12500], Loss: 1.1212, Acc: 63.83%\n",
      "Epoch 18, Validation Loss: 0.9165, Accuracy: 70.11%, LR: 0.000070\n",
      "Epoch [19/30], Batch [2000/12500], Loss: 1.1120, Acc: 64.47%\n",
      "Epoch [19/30], Batch [4000/12500], Loss: 1.0943, Acc: 65.62%\n",
      "Epoch [19/30], Batch [6000/12500], Loss: 1.1088, Acc: 64.74%\n",
      "Epoch [19/30], Batch [8000/12500], Loss: 1.0940, Acc: 65.30%\n",
      "Epoch [19/30], Batch [10000/12500], Loss: 1.0829, Acc: 65.62%\n",
      "Epoch [19/30], Batch [12000/12500], Loss: 1.1014, Acc: 64.85%\n",
      "Epoch 19, Validation Loss: 0.8606, Accuracy: 72.48%, LR: 0.000058\n",
      "Epoch [20/30], Batch [2000/12500], Loss: 1.0664, Acc: 66.44%\n",
      "Epoch [20/30], Batch [4000/12500], Loss: 1.0633, Acc: 66.31%\n",
      "Epoch [20/30], Batch [6000/12500], Loss: 1.0639, Acc: 66.31%\n",
      "Epoch [20/30], Batch [8000/12500], Loss: 1.0656, Acc: 66.85%\n",
      "Epoch [20/30], Batch [10000/12500], Loss: 1.0359, Acc: 67.08%\n",
      "Epoch [20/30], Batch [12000/12500], Loss: 1.0515, Acc: 66.90%\n",
      "Epoch 20, Validation Loss: 0.8485, Accuracy: 73.80%, LR: 0.000046\n",
      "Epoch [21/30], Batch [2000/12500], Loss: 1.0507, Acc: 67.15%\n",
      "Epoch [21/30], Batch [4000/12500], Loss: 1.0187, Acc: 68.04%\n",
      "Epoch [21/30], Batch [6000/12500], Loss: 1.0144, Acc: 67.92%\n",
      "Epoch [21/30], Batch [8000/12500], Loss: 1.0277, Acc: 67.65%\n",
      "Epoch [21/30], Batch [10000/12500], Loss: 1.0074, Acc: 68.41%\n",
      "Epoch [21/30], Batch [12000/12500], Loss: 0.9798, Acc: 69.36%\n",
      "Epoch 21, Validation Loss: 0.9107, Accuracy: 72.18%, LR: 0.000035\n",
      "Epoch [22/30], Batch [2000/12500], Loss: 0.9666, Acc: 69.84%\n",
      "Epoch [22/30], Batch [4000/12500], Loss: 0.9961, Acc: 69.21%\n",
      "Epoch [22/30], Batch [6000/12500], Loss: 0.9819, Acc: 69.03%\n",
      "Epoch [22/30], Batch [8000/12500], Loss: 0.9653, Acc: 69.80%\n",
      "Epoch [22/30], Batch [10000/12500], Loss: 0.9493, Acc: 70.54%\n",
      "Epoch [22/30], Batch [12000/12500], Loss: 0.9511, Acc: 70.08%\n",
      "Epoch 22, Validation Loss: 0.8070, Accuracy: 74.50%, LR: 0.000024\n",
      "Epoch [23/30], Batch [2000/12500], Loss: 0.9600, Acc: 70.24%\n",
      "Epoch [23/30], Batch [4000/12500], Loss: 0.9265, Acc: 71.53%\n",
      "Epoch [23/30], Batch [6000/12500], Loss: 0.9289, Acc: 70.97%\n",
      "Epoch [23/30], Batch [8000/12500], Loss: 0.8940, Acc: 72.65%\n",
      "Epoch [23/30], Batch [10000/12500], Loss: 0.9252, Acc: 71.47%\n",
      "Epoch [23/30], Batch [12000/12500], Loss: 0.9419, Acc: 70.95%\n",
      "Epoch 23, Validation Loss: 0.7736, Accuracy: 75.71%, LR: 0.000015\n",
      "Epoch [24/30], Batch [2000/12500], Loss: 0.9320, Acc: 71.44%\n",
      "Epoch [24/30], Batch [4000/12500], Loss: 0.9065, Acc: 72.06%\n",
      "Epoch [24/30], Batch [6000/12500], Loss: 0.8965, Acc: 72.56%\n",
      "Epoch [24/30], Batch [8000/12500], Loss: 0.9089, Acc: 72.03%\n",
      "Epoch [24/30], Batch [10000/12500], Loss: 0.8956, Acc: 72.62%\n",
      "Epoch [24/30], Batch [12000/12500], Loss: 0.8799, Acc: 73.08%\n",
      "Epoch 24, Validation Loss: 0.7187, Accuracy: 77.30%, LR: 0.000008\n",
      "Epoch [25/30], Batch [2000/12500], Loss: 0.8802, Acc: 72.83%\n",
      "Epoch [25/30], Batch [4000/12500], Loss: 0.8852, Acc: 72.70%\n",
      "Epoch [25/30], Batch [6000/12500], Loss: 0.8628, Acc: 73.47%\n",
      "Epoch [25/30], Batch [8000/12500], Loss: 0.8842, Acc: 72.85%\n",
      "Epoch [25/30], Batch [10000/12500], Loss: 0.8541, Acc: 74.31%\n",
      "Epoch [25/30], Batch [12000/12500], Loss: 0.8610, Acc: 73.53%\n",
      "Epoch 25, Validation Loss: 0.7411, Accuracy: 76.90%, LR: 0.000003\n",
      "Epoch [26/30], Batch [2000/12500], Loss: 0.8625, Acc: 73.72%\n",
      "Epoch [26/30], Batch [4000/12500], Loss: 0.8650, Acc: 73.51%\n",
      "Epoch [26/30], Batch [6000/12500], Loss: 0.8729, Acc: 73.56%\n",
      "Epoch [26/30], Batch [8000/12500], Loss: 0.8539, Acc: 73.72%\n",
      "Epoch [26/30], Batch [10000/12500], Loss: 0.8584, Acc: 73.58%\n",
      "Epoch [26/30], Batch [12000/12500], Loss: 0.8487, Acc: 74.24%\n",
      "Epoch 26, Validation Loss: 0.7234, Accuracy: 77.26%, LR: 0.000001\n",
      "Epoch [27/30], Batch [2000/12500], Loss: 0.8698, Acc: 73.58%\n",
      "Epoch [27/30], Batch [4000/12500], Loss: 0.9775, Acc: 69.31%\n",
      "Epoch [27/30], Batch [6000/12500], Loss: 1.1797, Acc: 62.92%\n",
      "Epoch [27/30], Batch [8000/12500], Loss: 1.1803, Acc: 62.64%\n",
      "Epoch [27/30], Batch [10000/12500], Loss: 1.1718, Acc: 62.94%\n",
      "Epoch [27/30], Batch [12000/12500], Loss: 1.1843, Acc: 61.79%\n",
      "Epoch 27, Validation Loss: 0.9765, Accuracy: 69.46%, LR: 0.000100\n",
      "Epoch [28/30], Batch [2000/12500], Loss: 1.1837, Acc: 63.01%\n",
      "Epoch [28/30], Batch [4000/12500], Loss: 1.1816, Acc: 62.31%\n",
      "Epoch [28/30], Batch [6000/12500], Loss: 1.1810, Acc: 62.65%\n",
      "Epoch [28/30], Batch [8000/12500], Loss: 1.2068, Acc: 61.60%\n",
      "Epoch [28/30], Batch [10000/12500], Loss: 1.1886, Acc: 62.84%\n",
      "Epoch [28/30], Batch [12000/12500], Loss: 1.1694, Acc: 62.98%\n",
      "Epoch 28, Validation Loss: 1.0296, Accuracy: 67.79%, LR: 0.000099\n",
      "Epoch [29/30], Batch [2000/12500], Loss: 1.1597, Acc: 63.26%\n",
      "Epoch [29/30], Batch [4000/12500], Loss: 1.2079, Acc: 61.11%\n",
      "Epoch [29/30], Batch [6000/12500], Loss: 1.1716, Acc: 62.60%\n",
      "Epoch [29/30], Batch [8000/12500], Loss: 1.1736, Acc: 62.38%\n",
      "Epoch [29/30], Batch [10000/12500], Loss: 1.1897, Acc: 61.98%\n",
      "Epoch [29/30], Batch [12000/12500], Loss: 1.1757, Acc: 61.90%\n",
      "Epoch 29, Validation Loss: 1.0447, Accuracy: 67.02%, LR: 0.000097\n",
      "Epoch [30/30], Batch [2000/12500], Loss: 1.1865, Acc: 62.92%\n",
      "Epoch [30/30], Batch [4000/12500], Loss: 1.1653, Acc: 62.85%\n",
      "Epoch [30/30], Batch [6000/12500], Loss: 1.1555, Acc: 63.29%\n",
      "Epoch [30/30], Batch [8000/12500], Loss: 1.1739, Acc: 63.04%\n",
      "Epoch [30/30], Batch [10000/12500], Loss: 1.1550, Acc: 62.16%\n",
      "Epoch [30/30], Batch [12000/12500], Loss: 1.1570, Acc: 63.27%\n",
      "Epoch 30, Validation Loss: 0.9447, Accuracy: 70.05%, LR: 0.000095\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "LR=0.0001\n",
    "criterion=nn.CrossEntropyLoss().cuda()\n",
    "optimizer=optim.Adam(model.parameters(),LR,weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=10,     # 第一次重启的周期\n",
    "    T_mult=2,   # 每次重启后周期倍增\n",
    "    eta_min=1e-6  # 最小学习率\n",
    ")\n",
    "max_grad_norm = 1.0  # 梯度裁剪阈值\n",
    "# 添加图像描述变量\n",
    "image_captions = []\n",
    "\n",
    "# 创建存储训练指标的列表\n",
    "train_losses = []\n",
    "val_losses = []  # 新增验证损失列表\n",
    "val_accuracies = []\n",
    "learning_rates = []\n",
    "epochs=30\n",
    "for epoch in range(epochs):\n",
    "    running_loss=0.0\n",
    "    total=0\n",
    "    correct=0\n",
    "    model.train()\n",
    "    # 添加当前epoch的图像描述\n",
    "    epoch_caption = f\"Epoch {epoch+1}/{epochs}: Training in progress...\"\n",
    "    image_captions.append(epoch_caption)\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels=data\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if i % 2000 == 1999:  # 每2000个batch打印一次\n",
    "            train_acc = 100 * correct / total\n",
    "            batch_caption = (f'Epoch [{epoch+1}/{epochs}], Batch [{i+1}/{len(trainloader)}], '\n",
    "                            f'Loss: {running_loss/2000:.4f}, Acc: {train_acc:.2f}%')\n",
    "            print(batch_caption)\n",
    "            image_captions.append(batch_caption)\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        learning_rates.append(current_lr)\n",
    "\n",
    "     # 验证过程\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    avg_val_loss = val_loss / len(testloader)\n",
    "    val_losses.append(avg_val_loss)  # 记录验证损失\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    epoch_summary = (f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}, '\n",
    "                    f'Accuracy: {val_acc:.2f}%, LR: {current_lr:.6f}')\n",
    "    print(epoch_summary)\n",
    "    image_captions.append(epoch_summary)\n",
    "    train_losses.append(val_loss)\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e100e296-ead2-41cf-ad40-f47664c89626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Model saved as final_model.pth\n",
      "Training report and accuracy plot saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# 保存最终模型\n",
    "torch.save(model.state_dict(), 'resnet50_model.pth')\n",
    "final_caption = \"Training completed. Model saved as final_model.pth\"\n",
    "print(final_caption)\n",
    "image_captions.append(final_caption)\n",
    "\n",
    "# 绘制测试集准确率变化折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs+1), val_accuracies, 'b-o', linewidth=2)\n",
    "plt.title('Test Accuracy Over Epochs', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.xticks(range(1, epochs+1))\n",
    "plt.ylim(0, 100)  # 确保y轴从0到100%\n",
    "\n",
    "# 标记最高准确率\n",
    "max_acc = max(val_accuracies)\n",
    "max_epoch = val_accuracies.index(max_acc) + 1\n",
    "plt.annotate(f'Max: {max_acc:.2f}%', \n",
    "             xy=(max_epoch, max_acc),\n",
    "             xytext=(max_epoch+1, max_acc-5),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "             fontsize=12)\n",
    "\n",
    "# 保存图表\n",
    "plt.savefig('accuracy_plot_resnet50.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 添加图表描述\n",
    "plot_caption = (\"Accuracy Plot: Shows the model's performance improvement on the test set over training epochs. \"\n",
    "               f\"Highest accuracy of {max_acc:.2f}% achieved at epoch {max_epoch}.\")\n",
    "image_captions.append(plot_caption)\n",
    "\n",
    "# 保存所有图像描述到文件\n",
    "with open('training_report.txt', 'w') as f:\n",
    "    for caption in image_captions:\n",
    "        f.write(caption + '\\n')\n",
    "\n",
    "print(\"Training report and accuracy plot saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c560520-76c7-4c5a-a3b1-d4e6a3b99b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
