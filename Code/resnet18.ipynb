{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bb19c2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-22T14:46:23.498937Z",
     "iopub.status.busy": "2025-10-22T14:46:23.498734Z",
     "iopub.status.idle": "2025-10-22T14:46:38.506645Z",
     "shell.execute_reply": "2025-10-22T14:46:38.505832Z"
    },
    "papermill": {
     "duration": 15.012124,
     "end_time": "2025-10-22T14:46:38.508151",
     "exception": false,
     "start_time": "2025-10-22T14:46:23.496027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:03<00:00, 53.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])  # ImageNet标准化\n",
    "])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((40, 40)),  # 先放大\n",
    "    transforms.RandomCrop(32),     # 再随机裁剪\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])  # ImageNet标准化\n",
    "])\n",
    "batch_size=4\n",
    "trainset=torchvision.datasets.CIFAR10(root=r'./',train=True,download=True,transform=transform_train)\n",
    "testset=torchvision.datasets.CIFAR10(root=r'./',train=False,download=True,transform=transform)\n",
    "trainloader=torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "testloader=torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "classes=('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed96a6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T14:46:38.515151Z",
     "iopub.status.busy": "2025-10-22T14:46:38.514840Z",
     "iopub.status.idle": "2025-10-22T14:46:38.525359Z",
     "shell.execute_reply": "2025-10-22T14:46:38.524858Z"
    },
    "papermill": {
     "duration": 0.014949,
     "end_time": "2025-10-22T14:46:38.526403",
     "exception": false,
     "start_time": "2025-10-22T14:46:38.511454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        # 主路径\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # 捷径连接\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)  # 残差连接\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        # 初始卷积层（适应CIFAR-10的32x32尺寸）\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # 残差块层\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        # 全局平均池化和全连接层\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "    \n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        # 创建包含多个残差块的层\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        \n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_channels, out_channels, stride=1))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "824005a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T14:46:38.532607Z",
     "iopub.status.busy": "2025-10-22T14:46:38.532406Z",
     "iopub.status.idle": "2025-10-22T16:36:29.514905Z",
     "shell.execute_reply": "2025-10-22T16:36:29.513912Z"
    },
    "papermill": {
     "duration": 6590.987332,
     "end_time": "2025-10-22T16:36:29.516398",
     "exception": false,
     "start_time": "2025-10-22T14:46:38.529066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Batch [2000/12500], Loss: 2.0560, Acc: 24.48%\n",
      "Epoch [1/30], Batch [4000/12500], Loss: 1.8791, Acc: 31.51%\n",
      "Epoch [1/30], Batch [6000/12500], Loss: 1.7467, Acc: 36.85%\n",
      "Epoch [1/30], Batch [8000/12500], Loss: 1.6657, Acc: 40.04%\n",
      "Epoch [1/30], Batch [10000/12500], Loss: 1.4743, Acc: 48.33%\n",
      "Epoch [1/30], Batch [12000/12500], Loss: 1.5766, Acc: 44.30%\n",
      "Epoch 1, Validation Loss: 1.3054, Accuracy: 53.67%, LR: 0.000088\n",
      "Epoch 1, Validation Loss: 3263.5979, Accuracy: 53.67%, LR: 0.000088\n",
      "Epoch [2/30], Batch [2000/12500], Loss: 1.4960, Acc: 46.17%\n",
      "Epoch [2/30], Batch [4000/12500], Loss: 1.3794, Acc: 51.14%\n",
      "Epoch [2/30], Batch [6000/12500], Loss: 1.2730, Acc: 55.06%\n",
      "Epoch [2/30], Batch [8000/12500], Loss: 1.2264, Acc: 56.66%\n",
      "Epoch [2/30], Batch [10000/12500], Loss: 1.4201, Acc: 50.10%\n",
      "Epoch [2/30], Batch [12000/12500], Loss: 1.3933, Acc: 50.71%\n",
      "Epoch 2, Validation Loss: 1.3026, Accuracy: 56.52%, LR: 0.000089\n",
      "Epoch 2, Validation Loss: 3256.4944, Accuracy: 56.52%, LR: 0.000089\n",
      "Epoch [3/30], Batch [2000/12500], Loss: 1.3109, Acc: 53.90%\n",
      "Epoch [3/30], Batch [4000/12500], Loss: 1.2711, Acc: 55.29%\n",
      "Epoch [3/30], Batch [6000/12500], Loss: 1.1820, Acc: 58.69%\n",
      "Epoch [3/30], Batch [8000/12500], Loss: 1.1536, Acc: 59.55%\n",
      "Epoch [3/30], Batch [10000/12500], Loss: 1.0921, Acc: 61.74%\n",
      "Epoch [3/30], Batch [12000/12500], Loss: 1.0511, Acc: 63.30%\n",
      "Epoch 3, Validation Loss: 1.0514, Accuracy: 66.91%, LR: 0.000008\n",
      "Epoch 3, Validation Loss: 2628.3831, Accuracy: 66.91%, LR: 0.000008\n",
      "Epoch [4/30], Batch [2000/12500], Loss: 0.9862, Acc: 65.62%\n",
      "Epoch [4/30], Batch [4000/12500], Loss: 1.0424, Acc: 63.92%\n",
      "Epoch [4/30], Batch [6000/12500], Loss: 1.2373, Acc: 56.99%\n",
      "Epoch [4/30], Batch [8000/12500], Loss: 1.2208, Acc: 57.23%\n",
      "Epoch [4/30], Batch [10000/12500], Loss: 1.2182, Acc: 57.91%\n",
      "Epoch [4/30], Batch [12000/12500], Loss: 1.1734, Acc: 59.21%\n",
      "Epoch 4, Validation Loss: 1.1627, Accuracy: 62.97%, LR: 0.000089\n",
      "Epoch 4, Validation Loss: 2906.6607, Accuracy: 62.97%, LR: 0.000089\n",
      "Epoch [5/30], Batch [2000/12500], Loss: 1.1546, Acc: 59.80%\n",
      "Epoch [5/30], Batch [4000/12500], Loss: 1.1162, Acc: 61.38%\n",
      "Epoch [5/30], Batch [6000/12500], Loss: 1.0774, Acc: 62.92%\n",
      "Epoch [5/30], Batch [8000/12500], Loss: 1.0585, Acc: 63.89%\n",
      "Epoch [5/30], Batch [10000/12500], Loss: 1.0288, Acc: 65.20%\n",
      "Epoch [5/30], Batch [12000/12500], Loss: 1.0000, Acc: 66.20%\n",
      "Epoch 5, Validation Loss: 1.1025, Accuracy: 67.07%, LR: 0.000046\n",
      "Epoch 5, Validation Loss: 2756.3259, Accuracy: 67.07%, LR: 0.000046\n",
      "Epoch [6/30], Batch [2000/12500], Loss: 0.9639, Acc: 66.62%\n",
      "Epoch [6/30], Batch [4000/12500], Loss: 0.9487, Acc: 67.66%\n",
      "Epoch [6/30], Batch [6000/12500], Loss: 0.9096, Acc: 69.14%\n",
      "Epoch [6/30], Batch [8000/12500], Loss: 0.8896, Acc: 69.95%\n",
      "Epoch [6/30], Batch [10000/12500], Loss: 0.8597, Acc: 70.39%\n",
      "Epoch [6/30], Batch [12000/12500], Loss: 0.8367, Acc: 71.64%\n",
      "Epoch 6, Validation Loss: 0.8950, Accuracy: 73.64%, LR: 0.000008\n",
      "Epoch 6, Validation Loss: 2237.4261, Accuracy: 73.64%, LR: 0.000008\n",
      "Epoch [7/30], Batch [2000/12500], Loss: 0.8059, Acc: 72.45%\n",
      "Epoch [7/30], Batch [4000/12500], Loss: 0.7937, Acc: 73.06%\n",
      "Epoch [7/30], Batch [6000/12500], Loss: 0.8001, Acc: 72.47%\n",
      "Epoch [7/30], Batch [8000/12500], Loss: 0.9408, Acc: 67.50%\n",
      "Epoch [7/30], Batch [10000/12500], Loss: 1.0588, Acc: 64.22%\n",
      "Epoch [7/30], Batch [12000/12500], Loss: 1.0934, Acc: 61.90%\n",
      "Epoch 7, Validation Loss: 1.0942, Accuracy: 65.96%, LR: 0.000099\n",
      "Epoch 7, Validation Loss: 2735.4856, Accuracy: 65.96%, LR: 0.000099\n",
      "Epoch [8/30], Batch [2000/12500], Loss: 1.0621, Acc: 63.76%\n",
      "Epoch [8/30], Batch [4000/12500], Loss: 1.0444, Acc: 63.84%\n",
      "Epoch [8/30], Batch [6000/12500], Loss: 1.0364, Acc: 64.40%\n",
      "Epoch [8/30], Batch [8000/12500], Loss: 1.0186, Acc: 65.08%\n",
      "Epoch [8/30], Batch [10000/12500], Loss: 1.0062, Acc: 65.06%\n",
      "Epoch [8/30], Batch [12000/12500], Loss: 1.0291, Acc: 64.26%\n",
      "Epoch 8, Validation Loss: 1.0099, Accuracy: 68.84%, LR: 0.000089\n",
      "Epoch 8, Validation Loss: 2524.7270, Accuracy: 68.84%, LR: 0.000089\n",
      "Epoch [9/30], Batch [2000/12500], Loss: 0.9656, Acc: 67.28%\n",
      "Epoch [9/30], Batch [4000/12500], Loss: 0.9899, Acc: 66.38%\n",
      "Epoch [9/30], Batch [6000/12500], Loss: 0.9707, Acc: 67.09%\n",
      "Epoch [9/30], Batch [8000/12500], Loss: 0.9262, Acc: 68.65%\n",
      "Epoch [9/30], Batch [10000/12500], Loss: 0.9247, Acc: 68.20%\n",
      "Epoch [9/30], Batch [12000/12500], Loss: 0.9172, Acc: 68.76%\n",
      "Epoch 9, Validation Loss: 0.8353, Accuracy: 73.19%, LR: 0.000070\n",
      "Epoch 9, Validation Loss: 2088.2842, Accuracy: 73.19%, LR: 0.000070\n",
      "Epoch [10/30], Batch [2000/12500], Loss: 0.8921, Acc: 69.96%\n",
      "Epoch [10/30], Batch [4000/12500], Loss: 0.8851, Acc: 69.91%\n",
      "Epoch [10/30], Batch [6000/12500], Loss: 0.8712, Acc: 70.39%\n",
      "Epoch [10/30], Batch [8000/12500], Loss: 0.8451, Acc: 71.21%\n",
      "Epoch [10/30], Batch [10000/12500], Loss: 0.8661, Acc: 70.92%\n",
      "Epoch [10/30], Batch [12000/12500], Loss: 0.8191, Acc: 72.06%\n",
      "Epoch 10, Validation Loss: 0.8258, Accuracy: 75.16%, LR: 0.000046\n",
      "Epoch 10, Validation Loss: 2064.4068, Accuracy: 75.16%, LR: 0.000046\n",
      "Epoch [11/30], Batch [2000/12500], Loss: 0.8053, Acc: 72.55%\n",
      "Epoch [11/30], Batch [4000/12500], Loss: 0.7813, Acc: 73.38%\n",
      "Epoch [11/30], Batch [6000/12500], Loss: 0.7979, Acc: 72.49%\n",
      "Epoch [11/30], Batch [8000/12500], Loss: 0.7666, Acc: 74.14%\n",
      "Epoch [11/30], Batch [10000/12500], Loss: 0.7624, Acc: 74.16%\n",
      "Epoch [11/30], Batch [12000/12500], Loss: 0.7529, Acc: 75.26%\n",
      "Epoch 11, Validation Loss: 0.7324, Accuracy: 77.99%, LR: 0.000024\n",
      "Epoch 11, Validation Loss: 1830.9105, Accuracy: 77.99%, LR: 0.000024\n",
      "Epoch [12/30], Batch [2000/12500], Loss: 0.7250, Acc: 75.41%\n",
      "Epoch [12/30], Batch [4000/12500], Loss: 0.7009, Acc: 76.72%\n",
      "Epoch [12/30], Batch [6000/12500], Loss: 0.7224, Acc: 76.11%\n",
      "Epoch [12/30], Batch [8000/12500], Loss: 0.6770, Acc: 77.71%\n",
      "Epoch [12/30], Batch [10000/12500], Loss: 0.6883, Acc: 77.14%\n",
      "Epoch [12/30], Batch [12000/12500], Loss: 0.6757, Acc: 77.51%\n",
      "Epoch 12, Validation Loss: 0.7850, Accuracy: 77.34%, LR: 0.000008\n",
      "Epoch 12, Validation Loss: 1962.5849, Accuracy: 77.34%, LR: 0.000008\n",
      "Epoch [13/30], Batch [2000/12500], Loss: 0.6312, Acc: 79.12%\n",
      "Epoch [13/30], Batch [4000/12500], Loss: 0.6374, Acc: 79.29%\n",
      "Epoch [13/30], Batch [6000/12500], Loss: 0.6355, Acc: 78.69%\n",
      "Epoch [13/30], Batch [8000/12500], Loss: 0.6323, Acc: 79.30%\n",
      "Epoch [13/30], Batch [10000/12500], Loss: 0.6394, Acc: 78.76%\n",
      "Epoch [13/30], Batch [12000/12500], Loss: 0.6139, Acc: 79.54%\n",
      "Epoch 13, Validation Loss: 0.6930, Accuracy: 79.57%, LR: 0.000001\n",
      "Epoch 13, Validation Loss: 1732.4570, Accuracy: 79.57%, LR: 0.000001\n",
      "Epoch [14/30], Batch [2000/12500], Loss: 0.6980, Acc: 77.19%\n",
      "Epoch [14/30], Batch [4000/12500], Loss: 0.9279, Acc: 68.59%\n",
      "Epoch [14/30], Batch [6000/12500], Loss: 0.9374, Acc: 68.94%\n",
      "Epoch [14/30], Batch [8000/12500], Loss: 0.9285, Acc: 68.91%\n",
      "Epoch [14/30], Batch [10000/12500], Loss: 0.9278, Acc: 69.16%\n",
      "Epoch [14/30], Batch [12000/12500], Loss: 0.9091, Acc: 69.42%\n",
      "Epoch 14, Validation Loss: 0.9103, Accuracy: 72.27%, LR: 0.000099\n",
      "Epoch 14, Validation Loss: 2275.7799, Accuracy: 72.27%, LR: 0.000099\n",
      "Epoch [15/30], Batch [2000/12500], Loss: 0.9048, Acc: 69.46%\n",
      "Epoch [15/30], Batch [4000/12500], Loss: 0.9258, Acc: 68.56%\n",
      "Epoch [15/30], Batch [6000/12500], Loss: 0.9041, Acc: 68.75%\n",
      "Epoch [15/30], Batch [8000/12500], Loss: 0.8831, Acc: 70.14%\n",
      "Epoch [15/30], Batch [10000/12500], Loss: 0.9294, Acc: 68.86%\n",
      "Epoch [15/30], Batch [12000/12500], Loss: 0.8817, Acc: 70.34%\n",
      "Epoch 15, Validation Loss: 0.8669, Accuracy: 73.63%, LR: 0.000095\n",
      "Epoch 15, Validation Loss: 2167.2493, Accuracy: 73.63%, LR: 0.000095\n",
      "Epoch [16/30], Batch [2000/12500], Loss: 0.8785, Acc: 70.62%\n",
      "Epoch [16/30], Batch [4000/12500], Loss: 0.8849, Acc: 70.24%\n",
      "Epoch [16/30], Batch [6000/12500], Loss: 0.8785, Acc: 70.40%\n",
      "Epoch [16/30], Batch [8000/12500], Loss: 0.8570, Acc: 70.86%\n",
      "Epoch [16/30], Batch [10000/12500], Loss: 0.8544, Acc: 71.00%\n",
      "Epoch [16/30], Batch [12000/12500], Loss: 0.8679, Acc: 70.78%\n",
      "Epoch 16, Validation Loss: 0.7324, Accuracy: 76.93%, LR: 0.000089\n",
      "Epoch 16, Validation Loss: 1830.9353, Accuracy: 76.93%, LR: 0.000089\n",
      "Epoch [17/30], Batch [2000/12500], Loss: 0.8253, Acc: 72.69%\n",
      "Epoch [17/30], Batch [4000/12500], Loss: 0.8467, Acc: 71.55%\n",
      "Epoch [17/30], Batch [6000/12500], Loss: 0.8175, Acc: 72.75%\n",
      "Epoch [17/30], Batch [8000/12500], Loss: 0.8291, Acc: 72.89%\n",
      "Epoch [17/30], Batch [10000/12500], Loss: 0.8236, Acc: 72.95%\n",
      "Epoch [17/30], Batch [12000/12500], Loss: 0.8277, Acc: 72.53%\n",
      "Epoch 17, Validation Loss: 0.8502, Accuracy: 75.23%, LR: 0.000080\n",
      "Epoch 17, Validation Loss: 2125.5639, Accuracy: 75.23%, LR: 0.000080\n",
      "Epoch [18/30], Batch [2000/12500], Loss: 0.8013, Acc: 73.11%\n",
      "Epoch [18/30], Batch [4000/12500], Loss: 0.7974, Acc: 73.33%\n",
      "Epoch [18/30], Batch [6000/12500], Loss: 0.8033, Acc: 73.21%\n",
      "Epoch [18/30], Batch [8000/12500], Loss: 0.7932, Acc: 73.47%\n",
      "Epoch [18/30], Batch [10000/12500], Loss: 0.7922, Acc: 73.65%\n",
      "Epoch [18/30], Batch [12000/12500], Loss: 0.7715, Acc: 74.84%\n",
      "Epoch 18, Validation Loss: 0.6837, Accuracy: 78.82%, LR: 0.000070\n",
      "Epoch 18, Validation Loss: 1709.1547, Accuracy: 78.82%, LR: 0.000070\n",
      "Epoch [19/30], Batch [2000/12500], Loss: 0.7514, Acc: 75.36%\n",
      "Epoch [19/30], Batch [4000/12500], Loss: 0.7641, Acc: 74.64%\n",
      "Epoch [19/30], Batch [6000/12500], Loss: 0.7486, Acc: 75.05%\n",
      "Epoch [19/30], Batch [8000/12500], Loss: 0.7445, Acc: 75.34%\n",
      "Epoch [19/30], Batch [10000/12500], Loss: 0.7286, Acc: 75.56%\n",
      "Epoch [19/30], Batch [12000/12500], Loss: 0.7599, Acc: 75.04%\n",
      "Epoch 19, Validation Loss: 0.7856, Accuracy: 78.03%, LR: 0.000058\n",
      "Epoch 19, Validation Loss: 1964.0245, Accuracy: 78.03%, LR: 0.000058\n",
      "Epoch [20/30], Batch [2000/12500], Loss: 0.7240, Acc: 76.28%\n",
      "Epoch [20/30], Batch [4000/12500], Loss: 0.7197, Acc: 76.31%\n",
      "Epoch [20/30], Batch [6000/12500], Loss: 0.7279, Acc: 76.17%\n",
      "Epoch [20/30], Batch [8000/12500], Loss: 0.6935, Acc: 77.67%\n",
      "Epoch [20/30], Batch [10000/12500], Loss: 0.7235, Acc: 76.49%\n",
      "Epoch [20/30], Batch [12000/12500], Loss: 0.6918, Acc: 77.24%\n",
      "Epoch 20, Validation Loss: 0.8006, Accuracy: 77.76%, LR: 0.000046\n",
      "Epoch 20, Validation Loss: 2001.4642, Accuracy: 77.76%, LR: 0.000046\n",
      "Epoch [21/30], Batch [2000/12500], Loss: 0.6961, Acc: 77.35%\n",
      "Epoch [21/30], Batch [4000/12500], Loss: 0.6780, Acc: 78.11%\n",
      "Epoch [21/30], Batch [6000/12500], Loss: 0.6673, Acc: 78.01%\n",
      "Epoch [21/30], Batch [8000/12500], Loss: 0.6927, Acc: 77.74%\n",
      "Epoch [21/30], Batch [10000/12500], Loss: 0.6930, Acc: 77.38%\n",
      "Epoch [21/30], Batch [12000/12500], Loss: 0.6680, Acc: 78.66%\n",
      "Epoch 21, Validation Loss: 0.7401, Accuracy: 78.91%, LR: 0.000035\n",
      "Epoch 21, Validation Loss: 1850.3221, Accuracy: 78.91%, LR: 0.000035\n",
      "Epoch [22/30], Batch [2000/12500], Loss: 0.6482, Acc: 79.17%\n",
      "Epoch [22/30], Batch [4000/12500], Loss: 0.6557, Acc: 78.60%\n",
      "Epoch [22/30], Batch [6000/12500], Loss: 0.6425, Acc: 79.67%\n",
      "Epoch [22/30], Batch [8000/12500], Loss: 0.6340, Acc: 79.84%\n",
      "Epoch [22/30], Batch [10000/12500], Loss: 0.6427, Acc: 79.21%\n",
      "Epoch [22/30], Batch [12000/12500], Loss: 0.5954, Acc: 81.04%\n",
      "Epoch 22, Validation Loss: 0.6817, Accuracy: 81.12%, LR: 0.000024\n",
      "Epoch 22, Validation Loss: 1704.3012, Accuracy: 81.12%, LR: 0.000024\n",
      "Epoch [23/30], Batch [2000/12500], Loss: 0.6107, Acc: 80.75%\n",
      "Epoch [23/30], Batch [4000/12500], Loss: 0.5945, Acc: 81.56%\n",
      "Epoch [23/30], Batch [6000/12500], Loss: 0.6181, Acc: 81.04%\n",
      "Epoch [23/30], Batch [8000/12500], Loss: 0.6010, Acc: 80.89%\n",
      "Epoch [23/30], Batch [10000/12500], Loss: 0.5788, Acc: 81.46%\n",
      "Epoch [23/30], Batch [12000/12500], Loss: 0.5830, Acc: 81.31%\n",
      "Epoch 23, Validation Loss: 0.6711, Accuracy: 81.85%, LR: 0.000015\n",
      "Epoch 23, Validation Loss: 1677.7680, Accuracy: 81.85%, LR: 0.000015\n",
      "Epoch [24/30], Batch [2000/12500], Loss: 0.5561, Acc: 82.58%\n",
      "Epoch [24/30], Batch [4000/12500], Loss: 0.5818, Acc: 81.83%\n",
      "Epoch [24/30], Batch [6000/12500], Loss: 0.5517, Acc: 82.90%\n",
      "Epoch [24/30], Batch [8000/12500], Loss: 0.5533, Acc: 83.19%\n",
      "Epoch [24/30], Batch [10000/12500], Loss: 0.5700, Acc: 82.58%\n",
      "Epoch [24/30], Batch [12000/12500], Loss: 0.5498, Acc: 83.35%\n",
      "Epoch 24, Validation Loss: 0.6511, Accuracy: 82.09%, LR: 0.000008\n",
      "Epoch 24, Validation Loss: 1627.7216, Accuracy: 82.09%, LR: 0.000008\n",
      "Epoch [25/30], Batch [2000/12500], Loss: 0.5394, Acc: 83.70%\n",
      "Epoch [25/30], Batch [4000/12500], Loss: 0.5486, Acc: 83.38%\n",
      "Epoch [25/30], Batch [6000/12500], Loss: 0.5176, Acc: 84.17%\n",
      "Epoch [25/30], Batch [8000/12500], Loss: 0.5531, Acc: 83.14%\n",
      "Epoch [25/30], Batch [10000/12500], Loss: 0.5382, Acc: 83.69%\n",
      "Epoch [25/30], Batch [12000/12500], Loss: 0.5421, Acc: 83.94%\n",
      "Epoch 25, Validation Loss: 0.6334, Accuracy: 83.48%, LR: 0.000003\n",
      "Epoch 25, Validation Loss: 1583.3976, Accuracy: 83.48%, LR: 0.000003\n",
      "Epoch [26/30], Batch [2000/12500], Loss: 0.5534, Acc: 83.11%\n",
      "Epoch [26/30], Batch [4000/12500], Loss: 0.5105, Acc: 84.39%\n",
      "Epoch [26/30], Batch [6000/12500], Loss: 0.5220, Acc: 84.12%\n",
      "Epoch [26/30], Batch [8000/12500], Loss: 0.5190, Acc: 84.49%\n",
      "Epoch [26/30], Batch [10000/12500], Loss: 0.5340, Acc: 84.06%\n",
      "Epoch [26/30], Batch [12000/12500], Loss: 0.4990, Acc: 84.31%\n",
      "Epoch 26, Validation Loss: 0.6083, Accuracy: 83.75%, LR: 0.000001\n",
      "Epoch 26, Validation Loss: 1520.8622, Accuracy: 83.75%, LR: 0.000001\n",
      "Epoch [27/30], Batch [2000/12500], Loss: 0.5249, Acc: 84.44%\n",
      "Epoch [27/30], Batch [4000/12500], Loss: 0.7293, Acc: 77.26%\n",
      "Epoch [27/30], Batch [6000/12500], Loss: 0.8349, Acc: 72.14%\n",
      "Epoch [27/30], Batch [8000/12500], Loss: 0.8378, Acc: 72.64%\n",
      "Epoch [27/30], Batch [10000/12500], Loss: 0.8287, Acc: 73.01%\n",
      "Epoch [27/30], Batch [12000/12500], Loss: 0.8334, Acc: 72.35%\n",
      "Epoch 27, Validation Loss: 0.9243, Accuracy: 74.32%, LR: 0.000100\n",
      "Epoch 27, Validation Loss: 2310.6383, Accuracy: 74.32%, LR: 0.000100\n",
      "Epoch [28/30], Batch [2000/12500], Loss: 0.8313, Acc: 72.64%\n",
      "Epoch [28/30], Batch [4000/12500], Loss: 0.8384, Acc: 72.89%\n",
      "Epoch [28/30], Batch [6000/12500], Loss: 0.8186, Acc: 73.71%\n",
      "Epoch [28/30], Batch [8000/12500], Loss: 0.8363, Acc: 72.21%\n",
      "Epoch [28/30], Batch [10000/12500], Loss: 0.8264, Acc: 72.60%\n",
      "Epoch [28/30], Batch [12000/12500], Loss: 0.8085, Acc: 73.31%\n",
      "Epoch 28, Validation Loss: 0.7613, Accuracy: 77.09%, LR: 0.000099\n",
      "Epoch 28, Validation Loss: 1903.2816, Accuracy: 77.09%, LR: 0.000099\n",
      "Epoch [29/30], Batch [2000/12500], Loss: 0.8049, Acc: 73.19%\n",
      "Epoch [29/30], Batch [4000/12500], Loss: 0.8149, Acc: 72.91%\n",
      "Epoch [29/30], Batch [6000/12500], Loss: 0.7980, Acc: 73.83%\n",
      "Epoch [29/30], Batch [8000/12500], Loss: 0.7974, Acc: 73.51%\n",
      "Epoch [29/30], Batch [10000/12500], Loss: 0.8171, Acc: 72.86%\n",
      "Epoch [29/30], Batch [12000/12500], Loss: 0.8151, Acc: 73.41%\n",
      "Epoch 29, Validation Loss: 0.8521, Accuracy: 75.69%, LR: 0.000097\n",
      "Epoch 29, Validation Loss: 2130.2490, Accuracy: 75.69%, LR: 0.000097\n",
      "Epoch [30/30], Batch [2000/12500], Loss: 0.7778, Acc: 74.15%\n",
      "Epoch [30/30], Batch [4000/12500], Loss: 0.7846, Acc: 74.35%\n",
      "Epoch [30/30], Batch [6000/12500], Loss: 0.7837, Acc: 73.96%\n",
      "Epoch [30/30], Batch [8000/12500], Loss: 0.7955, Acc: 73.65%\n",
      "Epoch [30/30], Batch [10000/12500], Loss: 0.7916, Acc: 73.88%\n",
      "Epoch [30/30], Batch [12000/12500], Loss: 0.7921, Acc: 73.85%\n",
      "Epoch 30, Validation Loss: 0.7510, Accuracy: 77.07%, LR: 0.000095\n",
      "Epoch 30, Validation Loss: 1877.5768, Accuracy: 77.07%, LR: 0.000095\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model=ResNet18().to(device)\n",
    "LR=0.0001\n",
    "criterion=nn.CrossEntropyLoss().cuda()\n",
    "optimizer=optim.Adam(model.parameters(),LR,weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=10,     # 第一次重启的周期\n",
    "    T_mult=2,   # 每次重启后周期倍增\n",
    "    eta_min=1e-6  # 最小学习率\n",
    ")\n",
    "max_grad_norm = 1.0  # 梯度裁剪阈值\n",
    "# 添加图像描述变量\n",
    "image_captions = []\n",
    "\n",
    "# 创建存储训练指标的列表\n",
    "train_losses = []\n",
    "val_losses = []  # 新增验证损失列表\n",
    "val_accuracies = []\n",
    "learning_rates = []\n",
    "epochs=30\n",
    "for epoch in range(epochs):\n",
    "    running_loss=0.0\n",
    "    total=0\n",
    "    correct=0\n",
    "    model.train()\n",
    "    # 添加当前epoch的图像描述\n",
    "    epoch_caption = f\"Epoch {epoch+1}/{epochs}: Training in progress...\"\n",
    "    image_captions.append(epoch_caption)\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels=data\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if i % 2000 == 1999:  # 每2000个batch打印一次\n",
    "            train_acc = 100 * correct / total\n",
    "            batch_caption = (f'Epoch [{epoch+1}/{epochs}], Batch [{i+1}/{len(trainloader)}], '\n",
    "                            f'Loss: {running_loss/2000:.4f}, Acc: {train_acc:.2f}%')\n",
    "            print(batch_caption)\n",
    "            image_captions.append(batch_caption)\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        learning_rates.append(current_lr)\n",
    "\n",
    "     # 验证过程\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    avg_val_loss = val_loss / len(testloader)\n",
    "    val_losses.append(avg_val_loss)  # 记录验证损失\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    epoch_summary = (f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}, '\n",
    "                    f'Accuracy: {val_acc:.2f}%, LR: {current_lr:.6f}')\n",
    "    print(epoch_summary)\n",
    "    image_captions.append(epoch_summary)\n",
    "    train_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%, LR: {current_lr:.6f}')\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cffbfd65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T16:36:29.538958Z",
     "iopub.status.busy": "2025-10-22T16:36:29.538692Z",
     "iopub.status.idle": "2025-10-22T16:36:30.383403Z",
     "shell.execute_reply": "2025-10-22T16:36:30.382590Z"
    },
    "papermill": {
     "duration": 0.857118,
     "end_time": "2025-10-22T16:36:30.384586",
     "exception": false,
     "start_time": "2025-10-22T16:36:29.527468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Model saved as final_model.pth\n",
      "Training report and accuracy plot saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# 保存最终模型\n",
    "torch.save(model.state_dict(), 'resnet_model.pth')\n",
    "final_caption = \"Training completed. Model saved as final_model.pth\"\n",
    "print(final_caption)\n",
    "image_captions.append(final_caption)\n",
    "\n",
    "# 绘制测试集准确率变化折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs+1), val_accuracies, 'b-o', linewidth=2)\n",
    "plt.title('Test Accuracy Over Epochs', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.xticks(range(1, epochs+1))\n",
    "plt.ylim(0, 100)  # 确保y轴从0到100%\n",
    "\n",
    "# 标记最高准确率\n",
    "max_acc = max(val_accuracies)\n",
    "max_epoch = val_accuracies.index(max_acc) + 1\n",
    "plt.annotate(f'Max: {max_acc:.2f}%', \n",
    "             xy=(max_epoch, max_acc),\n",
    "             xytext=(max_epoch+1, max_acc-5),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "             fontsize=12)\n",
    "\n",
    "# 保存图表\n",
    "plt.savefig('accuracy_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 添加图表描述\n",
    "plot_caption = (\"Accuracy Plot: Shows the model's performance improvement on the test set over training epochs. \"\n",
    "               f\"Highest accuracy of {max_acc:.2f}% achieved at epoch {max_epoch}.\")\n",
    "image_captions.append(plot_caption)\n",
    "\n",
    "# 保存所有图像描述到文件\n",
    "with open('training_report.txt', 'w') as f:\n",
    "    for caption in image_captions:\n",
    "        f.write(caption + '\\n')\n",
    "\n",
    "print(\"Training report and accuracy plot saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6611.879924,
   "end_time": "2025-10-22T16:36:31.915498",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-22T14:46:20.035574",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
