{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3313d64-58ea-419a-a7ce-ec2c0231855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])  # ImageNet标准化\n",
    "])\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((40, 40)),  # 先放大\n",
    "    transforms.RandomCrop(32),     # 再随机裁剪\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])  # ImageNet标准化\n",
    "])\n",
    "batch_size=4\n",
    "trainset=torchvision.datasets.CIFAR10(root=r'./',train=True,download=True,transform=transform_train)\n",
    "testset=torchvision.datasets.CIFAR10(root=r'./',train=False,download=True,transform=transform)\n",
    "trainloader=torch.utils.data.DataLoader(dataset=trainset,batch_size=batch_size,shuffle=True,num_workers=2)\n",
    "testloader=torch.utils.data.DataLoader(dataset=testset,batch_size=batch_size,shuffle=False,num_workers=2)\n",
    "classes=('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8eb61c-7e1d-4495-8d11-527207a267dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m vgg16.classifier[\u001b[32m6\u001b[39m] = nn.Linear(in_features=\u001b[32m4096\u001b[39m, out_features=\u001b[32m10\u001b[39m) \u001b[38;5;66;03m# 假设目标有10类\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 修改最后一层全连接层（适配10分类）\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m num_features = \u001b[43mmodel\u001b[49m.fc.in_features\n\u001b[32m     11\u001b[39m model.fc = nn.Sequential(\n\u001b[32m     12\u001b[39m     nn.Linear(num_features, \u001b[32m512\u001b[39m),\n\u001b[32m     13\u001b[39m     nn.ReLU(),\n\u001b[32m     14\u001b[39m     nn.Dropout(\u001b[32m0.5\u001b[39m),\n\u001b[32m     15\u001b[39m     nn.Linear(\u001b[32m512\u001b[39m, \u001b[32m10\u001b[39m)  \u001b[38;5;66;03m# CIFAR10有10个类别\u001b[39;00m\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# 启用新添加层的梯度\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from torch.nn import MultiheadAttention\n",
    "# 检查GPU可用性\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "vgg16 = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "vgg16.classifier[6] = nn.Linear(in_features=4096, out_features=10) # 假设目标有10类\n",
    "# 修改最后一层全连接层（适配10分类）\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 10)  # CIFAR10有10个类别\n",
    ")\n",
    "\n",
    "# 启用新添加层的梯度\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 转移到GPU（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ce3f7eb-e107-4218-9849-e09f600b533c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Batch [2000/12500], Loss: 1.6267, Acc: 43.76%\n",
      "Epoch [1/30], Batch [4000/12500], Loss: 1.3246, Acc: 56.96%\n",
      "Epoch [1/30], Batch [6000/12500], Loss: 1.1920, Acc: 62.62%\n",
      "Epoch [1/30], Batch [8000/12500], Loss: 1.1971, Acc: 62.75%\n",
      "Epoch [1/30], Batch [10000/12500], Loss: 0.9637, Acc: 70.29%\n",
      "Epoch [1/30], Batch [12000/12500], Loss: 1.1964, Acc: 63.62%\n",
      "Epoch 1, Validation Loss: 1.1238, Accuracy: 68.18%, LR: 0.000088\n",
      "Epoch [2/30], Batch [2000/12500], Loss: 1.1312, Acc: 65.96%\n",
      "Epoch [2/30], Batch [4000/12500], Loss: 0.9890, Acc: 70.33%\n",
      "Epoch [2/30], Batch [6000/12500], Loss: 0.8698, Acc: 73.89%\n",
      "Epoch [2/30], Batch [8000/12500], Loss: 0.7892, Acc: 75.86%\n",
      "Epoch [2/30], Batch [10000/12500], Loss: 1.1497, Acc: 66.31%\n",
      "Epoch [2/30], Batch [12000/12500], Loss: 1.1152, Acc: 67.58%\n",
      "Epoch 2, Validation Loss: 1.1847, Accuracy: 67.82%, LR: 0.000089\n",
      "Epoch [3/30], Batch [2000/12500], Loss: 1.0389, Acc: 69.61%\n",
      "Epoch [3/30], Batch [4000/12500], Loss: 1.0180, Acc: 70.36%\n",
      "Epoch [3/30], Batch [6000/12500], Loss: 0.9289, Acc: 72.36%\n",
      "Epoch [3/30], Batch [8000/12500], Loss: 0.8523, Acc: 75.30%\n",
      "Epoch [3/30], Batch [10000/12500], Loss: 0.8214, Acc: 75.85%\n",
      "Epoch [3/30], Batch [12000/12500], Loss: 0.7717, Acc: 77.34%\n",
      "Epoch 3, Validation Loss: 0.7357, Accuracy: 82.16%, LR: 0.000008\n",
      "Epoch [4/30], Batch [2000/12500], Loss: 0.7131, Acc: 79.49%\n",
      "Epoch [4/30], Batch [4000/12500], Loss: 0.7980, Acc: 77.74%\n",
      "Epoch [4/30], Batch [6000/12500], Loss: 1.0439, Acc: 69.66%\n",
      "Epoch [4/30], Batch [8000/12500], Loss: 1.0415, Acc: 69.38%\n",
      "Epoch [4/30], Batch [10000/12500], Loss: 1.0435, Acc: 69.54%\n",
      "Epoch [4/30], Batch [12000/12500], Loss: 0.9983, Acc: 70.75%\n",
      "Epoch 4, Validation Loss: 0.9362, Accuracy: 73.85%, LR: 0.000089\n",
      "Epoch [5/30], Batch [2000/12500], Loss: 0.9690, Acc: 72.86%\n",
      "Epoch [5/30], Batch [4000/12500], Loss: 0.9637, Acc: 72.30%\n",
      "Epoch [5/30], Batch [6000/12500], Loss: 0.9289, Acc: 73.38%\n",
      "Epoch [5/30], Batch [8000/12500], Loss: 0.9162, Acc: 73.94%\n",
      "Epoch [5/30], Batch [10000/12500], Loss: 0.8690, Acc: 74.62%\n",
      "Epoch [5/30], Batch [12000/12500], Loss: 0.8483, Acc: 76.09%\n",
      "Epoch 5, Validation Loss: 0.7127, Accuracy: 80.24%, LR: 0.000046\n",
      "Epoch [6/30], Batch [2000/12500], Loss: 0.8059, Acc: 77.39%\n",
      "Epoch [6/30], Batch [4000/12500], Loss: 0.7757, Acc: 77.70%\n",
      "Epoch [6/30], Batch [6000/12500], Loss: 0.7434, Acc: 78.60%\n",
      "Epoch [6/30], Batch [8000/12500], Loss: 0.6964, Acc: 80.89%\n",
      "Epoch [6/30], Batch [10000/12500], Loss: 0.7057, Acc: 79.89%\n",
      "Epoch [6/30], Batch [12000/12500], Loss: 0.6573, Acc: 81.36%\n",
      "Epoch 6, Validation Loss: 0.7268, Accuracy: 82.51%, LR: 0.000008\n",
      "Epoch [7/30], Batch [2000/12500], Loss: 0.6259, Acc: 82.61%\n",
      "Epoch [7/30], Batch [4000/12500], Loss: 0.6489, Acc: 81.86%\n",
      "Epoch [7/30], Batch [6000/12500], Loss: 0.6255, Acc: 82.44%\n",
      "Epoch [7/30], Batch [8000/12500], Loss: 0.8230, Acc: 77.69%\n",
      "Epoch [7/30], Batch [10000/12500], Loss: 0.9526, Acc: 72.60%\n",
      "Epoch [7/30], Batch [12000/12500], Loss: 0.9568, Acc: 72.36%\n",
      "Epoch 7, Validation Loss: 0.9398, Accuracy: 76.74%, LR: 0.000099\n",
      "Epoch [8/30], Batch [2000/12500], Loss: 0.9560, Acc: 72.47%\n",
      "Epoch [8/30], Batch [4000/12500], Loss: 0.9726, Acc: 71.61%\n",
      "Epoch [8/30], Batch [6000/12500], Loss: 0.9421, Acc: 72.35%\n",
      "Epoch [8/30], Batch [8000/12500], Loss: 0.9319, Acc: 73.28%\n",
      "Epoch [8/30], Batch [10000/12500], Loss: 0.9340, Acc: 73.34%\n",
      "Epoch [8/30], Batch [12000/12500], Loss: 0.9317, Acc: 73.04%\n",
      "Epoch 8, Validation Loss: 1.1153, Accuracy: 71.95%, LR: 0.000089\n",
      "Epoch [9/30], Batch [2000/12500], Loss: 0.9066, Acc: 74.94%\n",
      "Epoch [9/30], Batch [4000/12500], Loss: 0.9251, Acc: 73.08%\n",
      "Epoch [9/30], Batch [6000/12500], Loss: 0.8892, Acc: 74.25%\n",
      "Epoch [9/30], Batch [8000/12500], Loss: 0.8711, Acc: 75.15%\n",
      "Epoch [9/30], Batch [10000/12500], Loss: 0.8701, Acc: 75.11%\n",
      "Epoch [9/30], Batch [12000/12500], Loss: 0.8307, Acc: 75.97%\n",
      "Epoch 9, Validation Loss: 0.8151, Accuracy: 78.71%, LR: 0.000070\n",
      "Epoch [10/30], Batch [2000/12500], Loss: 0.8313, Acc: 76.21%\n",
      "Epoch [10/30], Batch [4000/12500], Loss: 0.8207, Acc: 76.80%\n",
      "Epoch [10/30], Batch [6000/12500], Loss: 0.8234, Acc: 77.22%\n",
      "Epoch [10/30], Batch [8000/12500], Loss: 0.7894, Acc: 78.03%\n",
      "Epoch [10/30], Batch [10000/12500], Loss: 0.8021, Acc: 77.33%\n",
      "Epoch [10/30], Batch [12000/12500], Loss: 0.7658, Acc: 78.35%\n",
      "Epoch 10, Validation Loss: 0.7919, Accuracy: 80.44%, LR: 0.000046\n",
      "Epoch [11/30], Batch [2000/12500], Loss: 0.7129, Acc: 80.24%\n",
      "Epoch [11/30], Batch [4000/12500], Loss: 0.7178, Acc: 79.62%\n",
      "Epoch [11/30], Batch [6000/12500], Loss: 0.7504, Acc: 78.86%\n",
      "Epoch [11/30], Batch [8000/12500], Loss: 0.7070, Acc: 80.44%\n",
      "Epoch [11/30], Batch [10000/12500], Loss: 0.7064, Acc: 80.65%\n",
      "Epoch [11/30], Batch [12000/12500], Loss: 0.7144, Acc: 80.28%\n",
      "Epoch 11, Validation Loss: 0.8079, Accuracy: 81.97%, LR: 0.000024\n",
      "Epoch [12/30], Batch [2000/12500], Loss: 0.6566, Acc: 82.00%\n",
      "Epoch [12/30], Batch [4000/12500], Loss: 0.6298, Acc: 82.51%\n",
      "Epoch [12/30], Batch [6000/12500], Loss: 0.6192, Acc: 82.90%\n",
      "Epoch [12/30], Batch [8000/12500], Loss: 0.6304, Acc: 83.36%\n",
      "Epoch [12/30], Batch [10000/12500], Loss: 0.6186, Acc: 82.59%\n",
      "Epoch [12/30], Batch [12000/12500], Loss: 0.5994, Acc: 83.81%\n",
      "Epoch 12, Validation Loss: 0.7036, Accuracy: 84.11%, LR: 0.000008\n",
      "Epoch [13/30], Batch [2000/12500], Loss: 0.5945, Acc: 83.84%\n",
      "Epoch [13/30], Batch [4000/12500], Loss: 0.5730, Acc: 84.04%\n",
      "Epoch [13/30], Batch [6000/12500], Loss: 0.5788, Acc: 84.42%\n",
      "Epoch [13/30], Batch [8000/12500], Loss: 0.5648, Acc: 84.53%\n",
      "Epoch [13/30], Batch [10000/12500], Loss: 0.5622, Acc: 84.33%\n",
      "Epoch [13/30], Batch [12000/12500], Loss: 0.5898, Acc: 84.28%\n",
      "Epoch 13, Validation Loss: 0.6932, Accuracy: 84.57%, LR: 0.000001\n",
      "Epoch [14/30], Batch [2000/12500], Loss: 0.6965, Acc: 81.08%\n",
      "Epoch [14/30], Batch [4000/12500], Loss: 0.8916, Acc: 74.85%\n",
      "Epoch [14/30], Batch [6000/12500], Loss: 0.9100, Acc: 74.59%\n",
      "Epoch [14/30], Batch [8000/12500], Loss: 0.9352, Acc: 73.69%\n",
      "Epoch [14/30], Batch [10000/12500], Loss: 0.9014, Acc: 73.95%\n",
      "Epoch [14/30], Batch [12000/12500], Loss: 0.9264, Acc: 74.09%\n",
      "Epoch 14, Validation Loss: 1.0085, Accuracy: 75.42%, LR: 0.000099\n",
      "Epoch [15/30], Batch [2000/12500], Loss: 0.9059, Acc: 73.74%\n",
      "Epoch [15/30], Batch [4000/12500], Loss: 0.8981, Acc: 74.86%\n",
      "Epoch [15/30], Batch [6000/12500], Loss: 0.9334, Acc: 73.76%\n",
      "Epoch [15/30], Batch [8000/12500], Loss: 0.8960, Acc: 74.33%\n",
      "Epoch [15/30], Batch [10000/12500], Loss: 0.9197, Acc: 73.67%\n",
      "Epoch [15/30], Batch [12000/12500], Loss: 0.9048, Acc: 74.70%\n",
      "Epoch 15, Validation Loss: 0.7523, Accuracy: 79.49%, LR: 0.000095\n",
      "Epoch [16/30], Batch [2000/12500], Loss: 0.8934, Acc: 75.05%\n",
      "Epoch [16/30], Batch [4000/12500], Loss: 0.8849, Acc: 74.34%\n",
      "Epoch [16/30], Batch [6000/12500], Loss: 0.8873, Acc: 74.88%\n",
      "Epoch [16/30], Batch [8000/12500], Loss: 0.8779, Acc: 75.35%\n",
      "Epoch [16/30], Batch [10000/12500], Loss: 0.8974, Acc: 74.94%\n",
      "Epoch [16/30], Batch [12000/12500], Loss: 0.8622, Acc: 75.33%\n",
      "Epoch 16, Validation Loss: 0.8406, Accuracy: 78.41%, LR: 0.000089\n",
      "Epoch [17/30], Batch [2000/12500], Loss: 0.8636, Acc: 75.44%\n",
      "Epoch [17/30], Batch [4000/12500], Loss: 0.8566, Acc: 76.10%\n",
      "Epoch [17/30], Batch [6000/12500], Loss: 0.8494, Acc: 75.89%\n",
      "Epoch [17/30], Batch [8000/12500], Loss: 0.8499, Acc: 75.51%\n",
      "Epoch [17/30], Batch [10000/12500], Loss: 0.8622, Acc: 75.34%\n",
      "Epoch [17/30], Batch [12000/12500], Loss: 0.8380, Acc: 76.81%\n",
      "Epoch 17, Validation Loss: 0.8491, Accuracy: 78.24%, LR: 0.000080\n",
      "Epoch [18/30], Batch [2000/12500], Loss: 0.8220, Acc: 76.79%\n",
      "Epoch [18/30], Batch [4000/12500], Loss: 0.8144, Acc: 77.24%\n",
      "Epoch [18/30], Batch [6000/12500], Loss: 0.8378, Acc: 76.50%\n",
      "Epoch [18/30], Batch [8000/12500], Loss: 0.8140, Acc: 77.04%\n",
      "Epoch [18/30], Batch [10000/12500], Loss: 0.8040, Acc: 77.17%\n",
      "Epoch [18/30], Batch [12000/12500], Loss: 0.8032, Acc: 77.88%\n",
      "Epoch 18, Validation Loss: 0.7753, Accuracy: 81.72%, LR: 0.000070\n",
      "Epoch [19/30], Batch [2000/12500], Loss: 0.7787, Acc: 78.66%\n",
      "Epoch [19/30], Batch [4000/12500], Loss: 0.7907, Acc: 77.70%\n",
      "Epoch [19/30], Batch [6000/12500], Loss: 0.7668, Acc: 78.49%\n",
      "Epoch [19/30], Batch [8000/12500], Loss: 0.7916, Acc: 78.76%\n",
      "Epoch [19/30], Batch [10000/12500], Loss: 0.7633, Acc: 79.03%\n",
      "Epoch [19/30], Batch [12000/12500], Loss: 0.7853, Acc: 78.74%\n",
      "Epoch 19, Validation Loss: 0.8335, Accuracy: 81.44%, LR: 0.000058\n",
      "Epoch [20/30], Batch [2000/12500], Loss: 0.7568, Acc: 79.30%\n",
      "Epoch [20/30], Batch [4000/12500], Loss: 0.7310, Acc: 80.33%\n",
      "Epoch [20/30], Batch [6000/12500], Loss: 0.7625, Acc: 79.30%\n",
      "Epoch [20/30], Batch [8000/12500], Loss: 0.7360, Acc: 79.22%\n",
      "Epoch [20/30], Batch [10000/12500], Loss: 0.7444, Acc: 79.41%\n",
      "Epoch [20/30], Batch [12000/12500], Loss: 0.7380, Acc: 80.35%\n",
      "Epoch 20, Validation Loss: 0.8024, Accuracy: 81.13%, LR: 0.000046\n",
      "Epoch [21/30], Batch [2000/12500], Loss: 0.7156, Acc: 80.50%\n",
      "Epoch [21/30], Batch [4000/12500], Loss: 0.7022, Acc: 81.26%\n",
      "Epoch [21/30], Batch [6000/12500], Loss: 0.7011, Acc: 80.65%\n",
      "Epoch [21/30], Batch [8000/12500], Loss: 0.7107, Acc: 80.70%\n",
      "Epoch [21/30], Batch [10000/12500], Loss: 0.6983, Acc: 80.72%\n",
      "Epoch [21/30], Batch [12000/12500], Loss: 0.6792, Acc: 80.81%\n",
      "Epoch 21, Validation Loss: 0.6797, Accuracy: 83.32%, LR: 0.000035\n",
      "Epoch [22/30], Batch [2000/12500], Loss: 0.6593, Acc: 81.83%\n",
      "Epoch [22/30], Batch [4000/12500], Loss: 0.6419, Acc: 82.80%\n",
      "Epoch [22/30], Batch [6000/12500], Loss: 0.6693, Acc: 81.91%\n",
      "Epoch [22/30], Batch [8000/12500], Loss: 0.6626, Acc: 82.33%\n",
      "Epoch [22/30], Batch [10000/12500], Loss: 0.6476, Acc: 82.61%\n",
      "Epoch [22/30], Batch [12000/12500], Loss: 0.6319, Acc: 83.12%\n",
      "Epoch 22, Validation Loss: 0.7031, Accuracy: 84.33%, LR: 0.000024\n",
      "Epoch [23/30], Batch [2000/12500], Loss: 0.6319, Acc: 83.36%\n",
      "Epoch [23/30], Batch [4000/12500], Loss: 0.6387, Acc: 82.46%\n",
      "Epoch [23/30], Batch [6000/12500], Loss: 0.6060, Acc: 83.66%\n",
      "Epoch [23/30], Batch [8000/12500], Loss: 0.6162, Acc: 84.04%\n",
      "Epoch [23/30], Batch [10000/12500], Loss: 0.6270, Acc: 83.22%\n",
      "Epoch [23/30], Batch [12000/12500], Loss: 0.5934, Acc: 83.54%\n",
      "Epoch 23, Validation Loss: 0.7789, Accuracy: 83.38%, LR: 0.000015\n",
      "Epoch [24/30], Batch [2000/12500], Loss: 0.5710, Acc: 84.55%\n",
      "Epoch [24/30], Batch [4000/12500], Loss: 0.6120, Acc: 83.50%\n",
      "Epoch [24/30], Batch [6000/12500], Loss: 0.5621, Acc: 85.08%\n",
      "Epoch [24/30], Batch [8000/12500], Loss: 0.5832, Acc: 84.26%\n",
      "Epoch [24/30], Batch [10000/12500], Loss: 0.5847, Acc: 84.46%\n",
      "Epoch [24/30], Batch [12000/12500], Loss: 0.5822, Acc: 85.00%\n",
      "Epoch 24, Validation Loss: 0.6625, Accuracy: 85.22%, LR: 0.000008\n",
      "Epoch [25/30], Batch [2000/12500], Loss: 0.5381, Acc: 85.83%\n",
      "Epoch [25/30], Batch [4000/12500], Loss: 0.5556, Acc: 85.90%\n",
      "Epoch [25/30], Batch [6000/12500], Loss: 0.5468, Acc: 85.24%\n",
      "Epoch [25/30], Batch [8000/12500], Loss: 0.5498, Acc: 85.72%\n",
      "Epoch [25/30], Batch [10000/12500], Loss: 0.5658, Acc: 85.60%\n",
      "Epoch [25/30], Batch [12000/12500], Loss: 0.5674, Acc: 84.83%\n",
      "Epoch 25, Validation Loss: 0.6747, Accuracy: 85.35%, LR: 0.000003\n",
      "Epoch [26/30], Batch [2000/12500], Loss: 0.5284, Acc: 85.91%\n",
      "Epoch [26/30], Batch [4000/12500], Loss: 0.5306, Acc: 86.34%\n",
      "Epoch [26/30], Batch [6000/12500], Loss: 0.5224, Acc: 86.21%\n",
      "Epoch [26/30], Batch [8000/12500], Loss: 0.5188, Acc: 85.94%\n",
      "Epoch [26/30], Batch [10000/12500], Loss: 0.5211, Acc: 86.28%\n",
      "Epoch [26/30], Batch [12000/12500], Loss: 0.5353, Acc: 86.00%\n",
      "Epoch 26, Validation Loss: 0.6885, Accuracy: 85.47%, LR: 0.000001\n",
      "Epoch [27/30], Batch [2000/12500], Loss: 0.5195, Acc: 85.96%\n",
      "Epoch [27/30], Batch [4000/12500], Loss: 0.7504, Acc: 79.60%\n",
      "Epoch [27/30], Batch [6000/12500], Loss: 0.8877, Acc: 75.95%\n",
      "Epoch [27/30], Batch [8000/12500], Loss: 0.8678, Acc: 75.56%\n",
      "Epoch [27/30], Batch [10000/12500], Loss: 0.8957, Acc: 74.66%\n",
      "Epoch [27/30], Batch [12000/12500], Loss: 0.8719, Acc: 75.47%\n",
      "Epoch 27, Validation Loss: 0.7211, Accuracy: 80.29%, LR: 0.000100\n",
      "Epoch [28/30], Batch [2000/12500], Loss: 0.8714, Acc: 75.39%\n",
      "Epoch [28/30], Batch [4000/12500], Loss: 0.8472, Acc: 76.24%\n",
      "Epoch [28/30], Batch [6000/12500], Loss: 0.8748, Acc: 75.65%\n",
      "Epoch [28/30], Batch [8000/12500], Loss: 0.8592, Acc: 75.65%\n",
      "Epoch [28/30], Batch [10000/12500], Loss: 0.8846, Acc: 75.35%\n",
      "Epoch [28/30], Batch [12000/12500], Loss: 0.8578, Acc: 75.92%\n",
      "Epoch 28, Validation Loss: 0.9089, Accuracy: 77.82%, LR: 0.000099\n",
      "Epoch [29/30], Batch [2000/12500], Loss: 0.8494, Acc: 75.92%\n",
      "Epoch [29/30], Batch [4000/12500], Loss: 0.8797, Acc: 75.24%\n",
      "Epoch [29/30], Batch [6000/12500], Loss: 0.8796, Acc: 74.34%\n",
      "Epoch [29/30], Batch [8000/12500], Loss: 0.8557, Acc: 76.36%\n",
      "Epoch [29/30], Batch [10000/12500], Loss: 0.8717, Acc: 76.01%\n",
      "Epoch [29/30], Batch [12000/12500], Loss: 0.8617, Acc: 75.58%\n",
      "Epoch 29, Validation Loss: 0.7959, Accuracy: 78.75%, LR: 0.000097\n",
      "Epoch [30/30], Batch [2000/12500], Loss: 0.8589, Acc: 76.12%\n",
      "Epoch [30/30], Batch [4000/12500], Loss: 0.8579, Acc: 76.54%\n",
      "Epoch [30/30], Batch [6000/12500], Loss: 0.8548, Acc: 75.94%\n",
      "Epoch [30/30], Batch [8000/12500], Loss: 0.8737, Acc: 75.78%\n",
      "Epoch [30/30], Batch [10000/12500], Loss: 0.8404, Acc: 76.36%\n",
      "Epoch [30/30], Batch [12000/12500], Loss: 0.8742, Acc: 75.78%\n",
      "Epoch 30, Validation Loss: 1.1534, Accuracy: 75.06%, LR: 0.000095\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model=vgg16.to(device)\n",
    "LR=0.0001\n",
    "criterion=nn.CrossEntropyLoss().cuda()\n",
    "optimizer=optim.Adam(model.parameters(),LR,weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=10,     # 第一次重启的周期\n",
    "    T_mult=2,   # 每次重启后周期倍增\n",
    "    eta_min=1e-6  # 最小学习率\n",
    ")\n",
    "max_grad_norm = 1.0  # 梯度裁剪阈值\n",
    "# 添加图像描述变量\n",
    "image_captions = []\n",
    "\n",
    "# 创建存储训练指标的列表\n",
    "train_losses = []\n",
    "val_losses = []  # 新增验证损失列表\n",
    "val_accuracies = []\n",
    "learning_rates = []\n",
    "epochs=30\n",
    "for epoch in range(epochs):\n",
    "    running_loss=0.0\n",
    "    total=0\n",
    "    correct=0\n",
    "    model.train()\n",
    "    # 添加当前epoch的图像描述\n",
    "    epoch_caption = f\"Epoch {epoch+1}/{epochs}: Training in progress...\"\n",
    "    image_captions.append(epoch_caption)\n",
    "    for i,data in enumerate(trainloader,0):\n",
    "        inputs,labels=data\n",
    "        inputs=inputs.cuda()\n",
    "        labels=labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if i % 2000 == 1999:  # 每2000个batch打印一次\n",
    "            train_acc = 100 * correct / total\n",
    "            batch_caption = (f'Epoch [{epoch+1}/{epochs}], Batch [{i+1}/{len(trainloader)}], '\n",
    "                            f'Loss: {running_loss/2000:.4f}, Acc: {train_acc:.2f}%')\n",
    "            print(batch_caption)\n",
    "            image_captions.append(batch_caption)\n",
    "            running_loss = 0.0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        learning_rates.append(current_lr)\n",
    "\n",
    "     # 验证过程\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    avg_val_loss = val_loss / len(testloader)\n",
    "    val_losses.append(avg_val_loss)  # 记录验证损失\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    epoch_summary = (f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}, '\n",
    "                    f'Accuracy: {val_acc:.2f}%, LR: {current_lr:.6f}')\n",
    "    print(epoch_summary)\n",
    "    image_captions.append(epoch_summary)\n",
    "    train_losses.append(val_loss)\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b6db42a-70d6-4e20-9dc5-4d6627e32e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Model saved as final_model.pth\n",
      "Training report and accuracy plot saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# 保存最终模型\n",
    "torch.save(model.state_dict(), 'vgg16_model.pth')\n",
    "final_caption = \"Training completed. Model saved as final_model.pth\"\n",
    "print(final_caption)\n",
    "image_captions.append(final_caption)\n",
    "\n",
    "# 绘制测试集准确率变化折线图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs+1), val_accuracies, 'b-o', linewidth=2)\n",
    "plt.title('Test Accuracy Over Epochs', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.xticks(range(1, epochs+1))\n",
    "plt.ylim(0, 100)  # 确保y轴从0到100%\n",
    "\n",
    "# 标记最高准确率\n",
    "max_acc = max(val_accuracies)\n",
    "max_epoch = val_accuracies.index(max_acc) + 1\n",
    "plt.annotate(f'Max: {max_acc:.2f}%', \n",
    "             xy=(max_epoch, max_acc),\n",
    "             xytext=(max_epoch+1, max_acc-5),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05),\n",
    "             fontsize=12)\n",
    "\n",
    "# 保存图表\n",
    "plt.savefig('accuracy_plot_vgg16.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 添加图表描述\n",
    "plot_caption = (\"Accuracy Plot: Shows the model's performance improvement on the test set over training epochs. \"\n",
    "               f\"Highest accuracy of {max_acc:.2f}% achieved at epoch {max_epoch}.\")\n",
    "image_captions.append(plot_caption)\n",
    "\n",
    "# 保存所有图像描述到文件\n",
    "with open('training_report.txt', 'w') as f:\n",
    "    for caption in image_captions:\n",
    "        f.write(caption + '\\n')\n",
    "\n",
    "print(\"Training report and accuracy plot saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71db744-cb9c-4008-a96b-b986e8e35b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
